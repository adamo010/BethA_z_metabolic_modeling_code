library(stringr) #for editing strings; a tidyverse creation
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
head(list.files(path)) #print a few file names in the file path
fnFs <- sort(list.files(path, pattern="_R1_001_trimmed.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001_trimmed.fastq.gz", full.names = TRUE))
fnFs[[1]]; fnRs[[1]] #this prints off the first element in each list (b/c R isn't 0- indexed like my old friend python)
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001_trimmed.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnFs[1:8])
plotQualityProfile(fnRs[1:8])
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxEE=c(2,2),
rm.phix=TRUE, minLen=175, truncLen=c(250,200))
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxEE=c(2,2),
rm.phix=TRUE, minLen=175, truncLen=c(250,200))
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread= TRUE)
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out
plotQualityProfile(filtFs[1:8])
plotQualityProfile(filtRs[1:8])
plotQualityProfile(filtFs[1])
plotQualityProfile(filtFs[2])
plotQualityProfile(filtFs[7])
plotQualityProfile(filtFs[8])
plotQualityProfile(filtFs[1,2,7,8])
plotQualityProfile(filtFs[1:2])
plotQualityProfile(filtFs[7:8])
errF <- learnErrors(filtFs, multithread=TRUE)
filtFs
errF <- learnErrors(filtFs, multithread=TRUE, matchIDs = TRUE)
table(file.exists(filtFs))
type(filtFs)
class(fitlFs)
class(filtFs)
filtFs
class(sample.names)
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
rm filtFs
rm(filtFs)
rm(filtRs)
sample.names2 <- sapply(strsplit(basename(fnFs), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
fnFs2 <- sort(list.files(path, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz"))
fnFs.2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
errF <- learnErrors(filtFs2, multithread=TRUE)
table(file.exists(filtFs)) #only four files exist
table(file.exists(filtFs2)) #only four files exist
errF <- learnErrors(filtFs2, multithread=TRUE)
filtFs2
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
errF <- learnErrors(filtFs2, multithread=TRUE)
table(file.exists(filtFs2)) #only four files exist
#FUCK THIS NOISE I HATE R. I'm moving the files that failed into a separate folder so I can create a new filtFs/filtRs "character",
filtFs2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed_filt.fastq.gz", full.names = TRUE))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
filtered_out2 #this prints the number of reads that are filtered in and out.
errF <- learnErrors(filtFs2, multithread=TRUE)
errR <- learnErrors(filtRs2, multithread=TRUE)
plotErrors(errF, nominalQ=TRUE)
dadaFs <- dada(filtFs2, err=errF, pool= "pseudo", multithread=TRUE) #specify files (filtFs2), errors (errF), turn ON pooling to detect rare
dadaRs <- dada(filtRs2, err=errR, pool= "pseudo", multithread=TRUE)
dadaFs[[1]]
filtFs2
dadaFs[[1]]
dadaFs[[2]]
dadaFs[[3]]
dadaFs[[4]]
dadaRs[[1]]
dadaRs[[2]]
dadaRs[[3]]
dadaRs[[4]]
mergers <- mergePairs(dadaFs, filtFs2, dadaRs, filtRs2, verbose=TRUE)
head(mergers[[1]])
seqtab <- makeSequenceTable(mergers)
table(nchar(getSequences(seqtab)))
dim(seqtab)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
sum(seqtab.nochim)/sum(seqtab)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
track <- cbind(filtered_out2, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names2
head(track)
taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "/Users/adamo010/Documents/Mayo_microbiome_project/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- addSpecies(taxa, "/Users/adamo010/Documents/Mayo_microbiome_project/silva_species_assignment_v138.1.fa.gz")
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
library(phyloseq)
source('http://bioconductor.org/biocLite.R')
biocLite('phyloseq')
source('http://bioconductor.org/biocLite.R')
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("phyloseq")
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")
View(seqtab.nochim)
for (i in 1:dim(seqtab.nochim)[2]) {asv_headers[i] <- paste(">ASV", i, sep="_")}
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "08.30.21_Mayo_microbiome_ASVs.fa")
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
asv_tax <- t(sapply(tax_info, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(asv_tax) <- ranks
rownames(asv_tax) <- gsub(pattern=">", replacement="", x=asv_headers)
asv_tax <- t(sapply(tax_info, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
asv_tax <- t(sapply(taxa, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
write.table(asv_tab, "08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
write(asv_fasta, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs.fa")
write.table(asv_tab, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
taxa
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
taxa
load("tax-info.RData")
download.file(url="http://www2.decipher.codes/Classification/TrainingSets/SILVA_SSU_r138_2019.RData", destfile="SILVA_SSU_r138_2019.RData")
load("SILVA_SSU_r138_2019.RData")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("DECIPHER")
library(DECIPHER)
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE) # use all processors
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
write.table(taxid, "ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
write.table(taxid, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
row.names(taxid) <- sub(">", "", asv_headers)
View(taxid)
View(taxid)
write.table(taxid, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
library(dada2); packageVersion("dada2") #this prints the package version that you're using. Here, I get 1.20.0.
library(stringr) #for editing strings; a tidyverse creation
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
head(list.files(path)) #print a few file names in the file path
fnFs <- sort(list.files(path, pattern="_R1_001_trimmed.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001_trimmed.fastq.gz", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001_trimmed.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
plotQualityProfile(fnFs[1:8])
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed_filt.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
rm(filtFs2, filtRs2)
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed.fastq.gz", full.names = TRUE))
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out2 <- filterAndTrim(fnFs, filtFs2, fnRs, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out3 <- filterAndTrim(fnFs, filtFs2, fnRs, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,5), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
plotQualityProfile(filtFs2[1:2])
sample.names
rm(list = ls()) #clear out environment as needed.
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses")
library("ggplot2")
library("readxl")
library("dplyr")
library("tidyverse")
library("ggpubr")
library("ape")
library("lme4")
library("gplots")
library("plotly")
library("tidyr")
library("vegan")
library("psych")
library("openxlsx")
library("magrittr")
library("purrr")
library("reshape2")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses/")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses/")
library(tidyverse)
library(broom)
library(palmerpenguins)
install palmerpenguins
install.packages("palmerpenguins")
library(palmerpenguins)
penguins <- penguins %>%
drop_na() %>%
select(-year)
View(penguins)
pca_fit <- penguins %>%
select(where(is.numeric)) %>%
scale() %>%
prcomp()
summary(pca_fit)
pca_fit %>%
augment(penguins)
pca_fit %>%
augment(penguins) %>%
rename_at(vars(starts_with(".fitted")),
list(~str_replace(.,".fitted","")))
pca_fit %>%
augment(penguins) %>%
rename_at(vars(starts_with(".fitted")),
list(~str_replace(.,".fitted",""))) %>%
ggplot(aes(x=PC1,
y=PC2,
color=species,
shape=sex))+
geom_point()
library("ggplot2")
library("readxl")
library("dplyr")
library("tidyverse")
library("ggpubr")
library("ape")
library("lme4")
library("gplots")
library("plotly")
library("tidyr")
library("vegan")
library("data.table")
library("stringr")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Analyzing_MICOM_communities_Niccolai2020/")
analyzed_fluxpaths <- read_csv("01.10.22_Niccolai2020_Fuso_fluxes_with_metadata_longform.csv")
analyzed_fluxpaths <- read_csv("01.10.22_Niccolai2020_Fuso_fluxes_with_metadata_longform.csv")
analyzed_fluxpaths$Patient_Blind_ID <- as.factor(analyzed_fluxpaths$Patient_Blind_ID)
View(analyzed_fluxpaths)
analyzed_fluxpaths <- analyzed_fluxpaths %>% rename(fluxpath_name= fluxpath_id,
fluxpath_subsystem= subsystem,
flux_value = fluxpath_values,
fluxpath_description = description)
fluxpaths_unique <- unique(analyzed_fluxpaths$fluxpath_name) #8621 fluxpaths
PBIDs_unique <- unique(analyzed_fluxpaths$Patient_Blind_ID) #23 PBIDs
subsystems_unique <- unique(analyzed_fluxpaths$fluxpath_subsystem) #22 PBIDs
rm(fluxpaths_unique, PBIDs_unique, subsystems_unique)
sum_fuso_fluxpaths <- subset(analyzed_fluxpaths, select = -c(OTU_ID))
sum_fuso_fluxpaths <- sum_fuso_fluxpaths %>%
mutate(sorting_col = paste0(SampleID, "_", fluxpath_name))
sum_fuso_fluxpaths$flux_value <- as.numeric(sum_fuso_fluxpaths$flux_value)
sum_fuso_fluxpaths$flux_value[is.na(sum_fuso_fluxpaths$flux_value)] <- 0
sum_fuso_fluxpaths_noNANs_collapsed <- sum_fuso_fluxpaths %>%        # Specify data frame
group_by(sorting_col, fluxpath_name, SampleID, fluxpath_description, Patient_Blind_ID, Description) %>%    # Specify group indicator (columns to keep)
summarise_at(vars(flux_value),                   # Specify column
list(sum_fluxpath_amount = sum)) %>% # Specify function
ungroup() #do this so select (dropping columns) can happen later
#nice. End up with a dataframe where
sum_fluxpaths_unique <- unique(sum_fuso_fluxpaths_noNANs_collapsed$fluxpath_name)
sum_fuso_fluxpaths_noNANs_collapsed <- sum_fuso_fluxpaths_noNANs_collapsed %>% rename(flux_value = sum_fluxpath_amount)
rm(sum_fuso_fluxpaths, sum_fluxpaths_unique)
analyzed_fluxpaths_subset <- subset(analyzed_fluxpaths, select = -c(...1, abbreviation, fluxpath_description, formula))
analyzed_fluxpaths_subset <- analyzed_fluxpaths_subset %>%
mutate(sorting_col = paste0(SampleID, "_", fluxpath_subsystem))
analyzed_fluxpaths_subset_noNANs <- analyzed_fluxpaths_subset[!is.na(analyzed_fluxpaths_subset$flux_value),]
analyzed_fluxpaths_subset_noNANs <- analyzed_fluxpaths_subset[!is.na(analyzed_fluxpaths_subset$flux_value),]
analyzed_fluxpaths_subset_averaged <- analyzed_fluxpaths_subset_noNANs %>%        # Specify data frame
group_by(sorting_col, SampleID, Description, Patient_Blind_ID, fluxpath_subsystem) %>%    # Specify group indicator (columns to keep)
summarise_at(vars(flux_value),                   # Specify column
list(av_fluxpath_amount = mean)) %>% # Specify function
ungroup() #do
fluxpaths_averaged_unique <- unique(analyzed_fluxpaths_subset_averaged$fluxpath_subsystem) #85 subsystems
rm(fluxpaths_averaged_unique, analyzed_fluxpaths_subset_noNANs, analyzed_fluxpaths_subset)
analyzed_fluxpaths_wide <- select(analyzed_fluxpaths_subset_averaged, -c(sorting_col, SampleID)) #drop unnecessary columns
#first, convert to wide form
analyzed_fluxpaths_wide <- analyzed_fluxpaths_wide %>%
spread(Description, av_fluxpath_amount)
analyzed_fluxpaths_wide_noNANs <- analyzed_fluxpaths_wide[!(is.na(analyzed_fluxpaths_wide$tumor) & is.na(analyzed_fluxpaths_wide$normal)),]
fluxpaths_unique_zerofree <- unique(analyzed_fluxpaths_wide_noNANs$fluxpath_subsystem) #count the number of metabolites
analyzed_fluxpaths_wide_noNANs$tumor[is.na(analyzed_fluxpaths_wide_noNANs$tumor)] = 0
analyzed_fluxpaths_wide_noNANs$normal[is.na(analyzed_fluxpaths_wide_noNANs$normal)] = 0
analyzed_fluxpaths_wide_noNANs$difference <- (analyzed_fluxpaths_wide_noNANs$tumor - analyzed_fluxpaths_wide_noNANs$normal)
analyzed_fluxpaths_wide_noNANs_zerofree <- analyzed_fluxpaths_wide_noNANs[(analyzed_fluxpaths_wide_noNANs$difference !=0),]
fluxpaths_zerofree_unique <- unique(analyzed_fluxpaths_wide_noNANs_zerofree$fluxpath_subsystem)
rm(fluxpaths_unique_zerofree, fluxpaths_zerofree_unique, analyzed_fluxpaths_wide_noNANs, analyzed_fluxpaths_wide, analyzed_fluxpaths_subset_averaged)
View(sum_fuso_fluxpaths_noNANs_collapsed)
View(analyzed_fluxpaths_wide_noNANs_zerofree)
analyzed_fluxpaths_filtering_df <- analyzed_fluxpaths_wide_noNANs_zerofree %>%  #create a new dataframe by filtering the old one
mutate(count_of_nonzeros = rowSums(.[3:4]!=0)) %>% #create a new column, count_of_nonzeroes, that counts # nonzero values in columns 3 and 4 for each row
group_by(fluxpath_subsystem) %>% #group by the column of interest
summarize(n = sum(count_of_nonzeros)) %>% #sums the count_of_nonzeros values within each fluxpath_subsystem and saves the value as n
mutate(n) #add n as a new column in the dataframe
analyzed_fluxpaths_filter_added <- dplyr::inner_join(analyzed_fluxpaths_wide_noNANs_zerofree, analyzed_fluxpaths_filtering_df, by= "fluxpath_subsystem")
analyzed_fluxpaths_filtered <- filter(analyzed_fluxpaths_filter_added, n >= 36)
#count number of unique metabolites left
fluxpaths_filtered_unique <- unique(analyzed_fluxpaths_filtered$fluxpath_subsystem)
View(analyzed_fluxpaths_filtered)
View(analyzed_fluxpaths_filter_added)
analyzed_fluxpaths_filtered <- filter(analyzed_fluxpaths_filter_added, n >= 72)
#count number of unique metabolites left
fluxpaths_filtered_unique <- unique(analyzed_fluxpaths_filtered$fluxpath_subsystem)
rm(fluxpaths_filtered_unique, analyzed_fluxpaths_wide_noNANs_zerofree)
fluxpaths_filtered_unique <- unique(analyzed_fluxpaths_filtered$fluxpath_subsystem)
analyzed_fluxpaths_filtered <- filter(analyzed_fluxpaths_filter_added, n >= 36)
#count number of unique metabolites left
fluxpaths_filtered_unique <- unique(analyzed_fluxpaths_filtered$fluxpath_subsystem)
analyzed_fluxpaths_filtered <- filter(analyzed_fluxpaths_filter_added, n >= 36)
#count number of unique metabolites left
fluxpaths_filtered_unique <- unique(analyzed_fluxpaths_filtered$fluxpath_subsystem)
rm(fluxpaths_filtered_unique, analyzed_fluxpaths_wide_noNANs_zerofree)
analyzed_fluxpaths_paired_only <- select(analyzed_fluxpaths_filtered, -c(difference, n))
#rename a couple of columns to make life easier later. Yeah, yeah, I know, this is the reverse of what I did before.
#analyzed_metabolites_paired_only <- analyzed_metabolites_paired_only %>% rename(normal= mean_genus_GR_normal, tumor= mean_genus_GR_tumor) #rename these columns
#convert to long form
analyzed_fluxpaths_paired_long <- reshape2::melt(data= analyzed_fluxpaths_paired_only,
id.vars= c("Patient_Blind_ID", "fluxpath_subsystem"),
variable.name = "Description",
value.name = "fluxpath_activity")
#split up by different subsystems and see where we get.
split_analyzed_fluxpaths_by_flux <- split(analyzed_fluxpaths_paired_long, with(analyzed_fluxpaths_paired_long, interaction(fluxpath_subsystem)), drop = TRUE)
by_flux_stats <- lapply(split_analyzed_fluxpaths_by_flux, function(df){wilcox.test(fluxpath_activity~Description, data=df, exact= FALSE, paired= TRUE)})
by_flux_pvals <- c() #initialize list
for (elem in by_flux_stats){
new_value = elem$p.value
by_flux_pvals <- c(by_flux_pvals, new_value)}
rm(new_value)
#make a list of q-values
by_flux_qvals <- p.adjust(by_flux_pvals, method = "fdr")
#make a list of genus_ids
flux_ids <- c()
for(elem in split_analyzed_fluxpaths_by_flux){
new_value = elem$fluxpath_subsystem[1]
flux_ids <- c(flux_ids, new_value)}
#merge all lists together.
fluxpath_statistics <- data.frame(flux_ids, by_flux_pvals, by_flux_qvals)
###########Step 6: clean up and remove extra variables
rm(elem, split_analyzed_fluxpaths_by_flux, by_flux_pvals, by_flux_qvals, flux_ids, new_value)
fluxpath_statistics <- fluxpath_statistics[order(fluxpath_statistics$by_flux_pvals),] #re-order by p-value
View(fluxpath_statistics)
write.csv(as.data.frame(fluxpath_statistics), file="01.10.22_Fusobacterium_flux_subsystems_stats_Niccolai2020_data.csv")
##########Step 8: save results as a csv file
fluxpath_statistics <- fluxpath_statistics[order(fluxpath_statistics$by_flux_qvals),] #re-order by q-value
fluxpath_statistics <- fluxpath_statistics %>% rename("fluxpath_name"="flux_ids")
write.csv(as.data.frame(fluxpath_statistics), file="01.10.22_Fusobacterium_flux_subsystems_stats_Niccolai2020_data.csv")
rm(list = ls()) #clear out environment as needed.
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Analyzing_MICOM_communities_Niccolai2020/")
##########Step 2: import data and adjust factors
analyzed_fluxpaths <- read_csv("01.10.22_Niccolai2020_Fuso_fluxes_with_metadata_longform.csv")
analyzed_fluxpaths$Patient_Blind_ID <- as.factor(analyzed_fluxpaths$Patient_Blind_ID)
analyzed_fluxpaths <- analyzed_fluxpaths %>% rename(fluxpath_name= fluxpath_id,
fluxpath_subsystem= subsystem,
flux_value = fluxpath_values,
fluxpath_description = description)
sum_fuso_fluxpaths <- subset(analyzed_fluxpaths, select = -c(OTU_ID))
#create a new sorting column to get unique values for each Sample_ID/Fluxpath_name combo
sum_fuso_fluxpaths <- sum_fuso_fluxpaths %>%
mutate(sorting_col = paste0(SampleID, "_", fluxpath_name))
#Drop NAN values; converting to zeroes screws with averages
sum_fuso_fluxpaths$flux_value <- as.numeric(sum_fuso_fluxpaths$flux_value)
sum_fuso_fluxpaths$flux_value[is.na(sum_fuso_fluxpaths$flux_value)] <- 0
#then sum across sorting col:
sum_fuso_fluxpaths_noNANs_collapsed <- sum_fuso_fluxpaths %>%        # Specify data frame
group_by(sorting_col, fluxpath_name, SampleID, fluxpath_description, Patient_Blind_ID, Description) %>%    # Specify group indicator (columns to keep)
summarise_at(vars(flux_value),                   # Specify column
list(sum_fluxpath_amount = sum)) %>% # Specify function
ungroup() #do this so select (dropping columns) can happen later
#nice. End up with a dataframe where each row is a unique subsystem/sample average of fluxes from pathways within that subsystem
#how many unique fluxes are we including here?
sum_fluxpaths_unique <- unique(sum_fuso_fluxpaths_noNANs_collapsed$fluxpath_name)
#rename for latter consistency in code
sum_fuso_fluxpaths_noNANs_collapsed <- sum_fuso_fluxpaths_noNANs_collapsed %>% rename(flux_value = sum_fluxpath_amount)
#clean up
rm(sum_fuso_fluxpaths, sum_fluxpaths_unique)
trace_minerals <- c("EX_ca2(e)", "EX_cobalt2(e)", "EX_cu2(e)", "EX_mg2(e)", "EX_mn2(e)", "EX_zn2(e)", "EX_k(e)", "EX_cl(e)", "EX_so4(e)")
fuso_fluxpaths_only_filtered <- sum_fuso_fluxpaths_noNANs_collapsed
fuso_fluxpaths_trace_minerals_only <- fuso_fluxpaths_only_filtered[fuso_fluxpaths_only_filtered$fluxpath_name %in% trace_minerals, ]
fuso_fluxpaths_trace_minerals_only <- fuso_fluxpaths_trace_minerals_only %>%
mutate(flux_value=signif(flux_value, 6))
trace_minerals_filtering_df <- fuso_fluxpaths_trace_minerals_only %>%  #create a new dataframe by filtering the old one
group_by(SampleID) %>% #group by the column of interest
summarize(n = n_distinct(flux_value)) #count the number of occurrences of each unique value in metabolite_amount and store as variable 'n'
fuso_fluxpaths_collapsed <-data.frame(fuso_fluxpaths_only_filtered) #copy the original dataframe
fuso_fluxpaths_collapsed$fluxpath_name[fuso_fluxpaths_collapsed$fluxpath_name== "EX_cobalt2(e)"] <- "Trace_elements_exchange"
fuso_fluxpaths_collapsed$fluxpath_description[fuso_fluxpaths_collapsed$fluxpath_description== "Co2+ exchange"] <- "Exchange of nine trace elements"
fuso_fluxpaths_collapsed<- fuso_fluxpaths_collapsed[!(fuso_fluxpaths_collapsed$fluxpath_name %in% trace_minerals),]
fuso_fluxpaths_collapsed<- fuso_fluxpaths_collapsed[!(fuso_fluxpaths_collapsed$fluxpath_name %in% trace_minerals),]
fuso_fluxpaths_collapsed_unique <- unique(fuso_fluxpaths_collapsed$fluxpath_name)
rm(fuso_fluxpaths_collapsed_unique, fuso_fluxpaths_trace_minerals_only, trace_minerals_filtering_df, trace_minerals, fuso_fluxpaths_noNANs_unique)
fuso_fluxpaths_wide <- select(fuso_fluxpaths_collapsed, -c(SampleID)) #drop SampleID column
fuso_fluxpaths_wide <- fuso_fluxpaths_wide %>%
spread(Description, flux_value)
fuso_fluxpaths_wide_noNANs <- fuso_fluxpaths_wide[!(is.na(fuso_fluxpaths_wide$tumor) & is.na(fuso_fluxpaths_wide$normal)),]
fuso_fluxpaths_noNANs_unique <- unique(fuso_fluxpaths_wide_noNANs$fluxpath_name) #count the number of metabolites
#replace remaining NA values with zeroes
fuso_fluxpaths_wide_noNANs$tumor[is.na(fuso_fluxpaths_wide_noNANs$tumor)] = 0
fuso_fluxpaths_wide_noNANs$normal[is.na(fuso_fluxpaths_wide_noNANs$normal)] = 0
fuso_fluxpaths_wide_noNANs$difference <- (fuso_fluxpaths_wide_noNANs$tumor - fuso_fluxpaths_wide_noNANs$normal)
#remove any rows where differences are 0
fuso_fluxpaths_wide_noNANs_zerofree <- fuso_fluxpaths_wide_noNANs[(fuso_fluxpaths_wide_noNANs$difference !=0),]
#how many unique fluxes are we including here? 112
fuso_fluxpaths_zerofree_unique <- unique(fuso_fluxpaths_wide_noNANs_zerofree$fluxpath_name)
rm(fuso_fluxpaths_wide, fuso_fluxpaths_wide_noNANs, fuso_fluxpaths_noNANs_unique, fuso_fluxpaths_zerofree_unique)
num_fuso_pos_samples <- unique(fuso_fluxpaths_only_filtered$SampleID) #46 samples, here.CHECK.
View(fuso_fluxpaths_wide_noNANs_zerofree)
fuso_fluxpaths_filtering_df <- fuso_fluxpaths_wide_noNANs_zerofree %>%  #create a new dataframe by filtering the old one
mutate(count_of_nonzeros = rowSums(.[5:6]!=0)) %>% #create a new column, count_of_nonzeroes, that counts # nonzero values in tumor and normal columns
group_by(fluxpath_name) %>% #group by the column of interest
summarize(n = sum(count_of_nonzeros)) %>% #sums the count_of_nonzeros values within each fluxpath_subsystem and saves the value as n
mutate(n) #add n as a new column in the dataframe
#create a new dataframe that merges the old and new dataframes
fuso_fluxpaths_filter_added <- dplyr::inner_join(fuso_fluxpaths_wide_noNANs_zerofree, fuso_fluxpaths_filtering_df, by= "fluxpath_name")
fuso_fluxpaths_abundance_filtered <- filter(fuso_fluxpaths_filter_added, n >= 36)
fuso_fluxpaths_filtered_unique <- unique(fuso_fluxpaths_abundance_filtered$fluxpath_name)
rm(fuso_fluxpaths_filtering_df,fuso_fluxpaths_filter_added, fuso_fluxpaths_only_filtered, num_fuso_pos_samples, fuso_fluxpaths_filtered_unique, fuso_fluxpaths_wide_noNANs_zerofree)
#fuso_fluxpaths_abundance_filtered <- fuso_fluxpaths_abundance_filtered %>%  rename(fluxpath_description= description)
fuso_fluxpaths_paired_only <- select(fuso_fluxpaths_abundance_filtered, -c(difference, n, fluxpath_description, sorting_col))
#convert to long form
fuso_fluxpaths_paired_long <- reshape2::melt(data= fuso_fluxpaths_paired_only,
id.vars= c("Patient_Blind_ID", "fluxpath_name"),
variable.name = "Description",
value.name = "fluxpath_activity")
#split up by different subsystems and see where we get.
fuso_split_analyzed_fluxpaths_by_flux <- split(fuso_fluxpaths_paired_long,
with(fuso_fluxpaths_paired_long, interaction(fluxpath_name)), drop = TRUE)
fuso_by_flux_stats <- lapply(fuso_split_analyzed_fluxpaths_by_flux, function(df){wilcox.test(fluxpath_activity~Description, data=df, exact= FALSE, paired= TRUE)})
#make lists of p values
by_flux_pvals <- c() #initialize list
for (elem in fuso_by_flux_stats){
new_value = elem$p.value
by_flux_pvals <- c(by_flux_pvals, new_value)}
rm(new_value)
#make a list of q-values
by_flux_qvals <- p.adjust(by_flux_pvals, method = "fdr")
#make a list of genus_ids
flux_ids <- c()
for(elem in fuso_split_analyzed_fluxpaths_by_flux){
new_value = elem$fluxpath_name[1]
flux_ids <- c(flux_ids, new_value)}
fuso_fluxpath_statistics <- data.frame(flux_ids, by_flux_pvals, by_flux_qvals)
rm(elem, fuso_split_analyzed_fluxpaths_by_flux, by_flux_pvals, by_flux_qvals, flux_ids, new_value)
fuso_fluxpath_statistics <- fuso_fluxpath_statistics[order(fuso_fluxpath_statistics$by_flux_qvals),] #re-order by q-value
fuso_fluxpath_statistics <- fuso_fluxpath_statistics %>% rename("fluxpath_name"="flux_ids")
#I would also like to add back the descriptions, please.
#fuso_fluxpaths_collapsed <- fuso_fluxpaths_collapsed %>%  rename(fluxpath_description= description)
fluxpath_key <- subset(fuso_fluxpaths_collapsed, select = c(fluxpath_name, fluxpath_description) )
fluxpath_key <- fluxpath_key %>% distinct(fluxpath_name, .keep_all = TRUE)
#create a new dataframe that merges the old and new dataframes
fuso_fluxpath_statistics2 <- dplyr::inner_join(fuso_fluxpath_statistics, fluxpath_key, by= "fluxpath_name")
write.csv(as.data.frame(fuso_fluxpath_statistics2), file="01.10.22_Fusobacterium_all_flux_stats_Niccolai2020_data.csv")
write.csv(as.data.frame(fuso_fluxpath_statistics2), file="01.10.22_Fusobacterium_all_flux_stats_Niccolai2020_data.csv")
