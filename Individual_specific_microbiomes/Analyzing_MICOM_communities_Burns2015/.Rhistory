growth_rates_top_genera$growth_rate_tumor <- growth_rates_top_genera$growth_rate_tumor + 1
View(top_ten_genera)
View(growth_rates_top_genera)
growth_rates_top_genera[,c("log2_growth_rate_normal","log2_growth_rate_tumor")] <- log2(growth_rates_top_genera[,c("growth_rate_normal","growth_rate_tumor")])
View(growth_rates_top_genera)
growth_rates_top_genera$log2GRdiff <- (growth_rates_top_genera$log2_growth_rate_tumor - growth_rates_top_genera$log2_growth_rate_normal)
View(growth_rates_top_genera)
write.csv(as.data.frame(growth_rates_top_genera), file="04.13.21_most_differentially_growing_genera_log2_transformed.csv")
library(dada2)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.11")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("dada2", version = "3.13")
library(dada2); packageVersion("dada2") #this prints the package version that you're using. I installed 3.13, so that should be it.
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
head(list.files(path))
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz", full.names = TRUE))
fnFs[[1]]; fnRs[[1]]
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
library(stringr)
sample.names <- sapply(fnFs %>% str_replace("_R1_001.fastq.gz", ""))
sample.names <- sapply(substr(fnFs,1,nchar(fnFs)-16))
sample.names <- sapply(substr(basename(fnFs),1,nchar(fnFs)-16))
sample.names <- sapply(lapply(gsub('.{16}$', '', fnFs)))
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001.fastq.gz"), `[`, 1)
sample.names
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnFs[3:4])
plotQualityProfile(fnFs[5:6])
plotQualityProfile(fnFs[7:8])
plotQualityProfile(fnRs[1:2])
plotQualityProfile(fnRs[3:4])
plotQualityProfile(fnRs[5:6])
plotQualityProfile(fnRs[7:8])
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(285,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
out
plotQualityProfile(filtFs[1:2])
plotQualityProfile(filtFs[1:2])
plotQualityProfile(filtFs[3:4])
plotQualityProfile(filtFs[5:6])
plotQualityProfile(filtFs[5:6])
plotQualityProfile(filtFs[7:8])
plotQualityProfile(filtRs[1:2])
plotQualityProfile(filtRs[3:4])
plotQualityProfile(filtRs[5:6])
plotQualityProfile(filtRs[7:8])
library(dada2); packageVersion("dada2") #this prints the package version that you're using. Here, I get 1.20.0.
library(stringr) #for editing strings; a tidyverse creation
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
head(list.files(path)) #print a few file names in the file path
fnFs <- sort(list.files(path, pattern="_R1_001_trimmed.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001_trimmed.fastq.gz", full.names = TRUE))
fnFs[[1]]; fnRs[[1]] #this prints off the first element in each list (b/c R isn't 0- indexed like my old friend python)
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001_trimmed.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnFs[1:8])
plotQualityProfile(fnRs[1:8])
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxEE=c(2,2),
rm.phix=TRUE, minLen=175, truncLen=c(250,200))
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, maxEE=c(2,2),
rm.phix=TRUE, minLen=175, truncLen=c(250,200))
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread= TRUE)
filtered_out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out
plotQualityProfile(filtFs[1:8])
plotQualityProfile(filtRs[1:8])
plotQualityProfile(filtFs[1])
plotQualityProfile(filtFs[2])
plotQualityProfile(filtFs[7])
plotQualityProfile(filtFs[8])
plotQualityProfile(filtFs[1,2,7,8])
plotQualityProfile(filtFs[1:2])
plotQualityProfile(filtFs[7:8])
errF <- learnErrors(filtFs, multithread=TRUE)
filtFs
errF <- learnErrors(filtFs, multithread=TRUE, matchIDs = TRUE)
table(file.exists(filtFs))
type(filtFs)
class(fitlFs)
class(filtFs)
filtFs
class(sample.names)
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
rm filtFs
rm(filtFs)
rm(filtRs)
sample.names2 <- sapply(strsplit(basename(fnFs), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
fnFs2 <- sort(list.files(path, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz"))
fnFs.2 <- sort(list.files(path, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, "filtered", pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names, "_R_trimmed_filt.fastq.gz"))
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
errF <- learnErrors(filtFs2, multithread=TRUE)
table(file.exists(filtFs)) #only four files exist
table(file.exists(filtFs2)) #only four files exist
errF <- learnErrors(filtFs2, multithread=TRUE)
filtFs2
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
errF <- learnErrors(filtFs2, multithread=TRUE)
table(file.exists(filtFs2)) #only four files exist
#FUCK THIS NOISE I HATE R. I'm moving the files that failed into a separate folder so I can create a new filtFs/filtRs "character",
filtFs2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed_filt.fastq.gz", full.names = TRUE))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
filtered_out2 #this prints the number of reads that are filtered in and out.
errF <- learnErrors(filtFs2, multithread=TRUE)
errR <- learnErrors(filtRs2, multithread=TRUE)
plotErrors(errF, nominalQ=TRUE)
dadaFs <- dada(filtFs2, err=errF, pool= "pseudo", multithread=TRUE) #specify files (filtFs2), errors (errF), turn ON pooling to detect rare
dadaRs <- dada(filtRs2, err=errR, pool= "pseudo", multithread=TRUE)
dadaFs[[1]]
filtFs2
dadaFs[[1]]
dadaFs[[2]]
dadaFs[[3]]
dadaFs[[4]]
dadaRs[[1]]
dadaRs[[2]]
dadaRs[[3]]
dadaRs[[4]]
mergers <- mergePairs(dadaFs, filtFs2, dadaRs, filtRs2, verbose=TRUE)
head(mergers[[1]])
seqtab <- makeSequenceTable(mergers)
table(nchar(getSequences(seqtab)))
dim(seqtab)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
sum(seqtab.nochim)/sum(seqtab)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
track <- cbind(filtered_out2, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names2
head(track)
taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
taxa <- assignTaxonomy(seqtab.nochim, "~/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "~/tax/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- assignTaxonomy(seqtab.nochim, "/Users/adamo010/Documents/Mayo_microbiome_project/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa <- addSpecies(taxa, "/Users/adamo010/Documents/Mayo_microbiome_project/silva_species_assignment_v138.1.fa.gz")
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
library(phyloseq)
source('http://bioconductor.org/biocLite.R')
biocLite('phyloseq')
source('http://bioconductor.org/biocLite.R')
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("phyloseq")
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")
View(seqtab.nochim)
for (i in 1:dim(seqtab.nochim)[2]) {asv_headers[i] <- paste(">ASV", i, sep="_")}
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "08.30.21_Mayo_microbiome_ASVs.fa")
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
write.table(asv_tab, "08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
asv_tax <- t(sapply(tax_info, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(asv_tax) <- ranks
rownames(asv_tax) <- gsub(pattern=">", replacement="", x=asv_headers)
asv_tax <- t(sapply(tax_info, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
asv_tax <- t(sapply(taxa, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
write.table(asv_tab, "08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
write(asv_fasta, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs.fa")
write.table(asv_tab, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_counts.tsv", sep="\t", quote=F, col.names=NA)
taxa
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species")
taxa
load("tax-info.RData")
download.file(url="http://www2.decipher.codes/Classification/TrainingSets/SILVA_SSU_r138_2019.RData", destfile="SILVA_SSU_r138_2019.RData")
load("SILVA_SSU_r138_2019.RData")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("DECIPHER")
library(DECIPHER)
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs
ids <- IdTaxa(dna, trainingSet, strand="top", processors=NULL, verbose=FALSE) # use all processors
ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest
taxid <- t(sapply(ids, function(x) {
m <- match(ranks, x$rank)
taxa <- x$taxon[m]
taxa[startsWith(taxa, "unclassified_")] <- NA
taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
write.table(taxid, "ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
write.table(taxid, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
row.names(taxid) <- sub(">", "", asv_headers)
View(taxid)
View(taxid)
write.table(taxid, "/Users/adamo010/Documents/Mayo_microbiome_project/08.30.21_Mayo_microbiome_ASVs_taxonomy.tsv", sep = "\t", quote=F, col.names=NA)
library(dada2); packageVersion("dada2") #this prints the package version that you're using. Here, I get 1.20.0.
library(stringr) #for editing strings; a tidyverse creation
path <- "/Users/adamo010/Documents/Mayo_microbiome_project/"
head(list.files(path)) #print a few file names in the file path
fnFs <- sort(list.files(path, pattern="_R1_001_trimmed.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001_trimmed.fastq.gz", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001_trimmed.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
plotQualityProfile(fnFs[1:8])
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed_filt.fastq.gz", full.names = TRUE))
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed_filt.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
rm(filtFs2, filtRs2)
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
path2 <- "/Users/adamo010/Documents/Mayo_microbiome_project/filtered/"
fnFs2 <- sort(list.files(path2, pattern="_F_trimmed.fastq.gz", full.names = TRUE))
fnRs2 <- sort(list.files(path2, pattern="_R_trimmed.fastq.gz", full.names = TRUE))
sample.names2 <- sapply(strsplit(basename(fnFs2), "_trimmed_filt.fastq.gz"), `[`, 1) #this creates a list called sample_names based on fnFs, which has _R1_001.fastq.gz trimmed
filtFs2 <- file.path(path, "filtered", paste0(sample.names2, "_F_trimmed_filt.fastq.gz"))
filtRs2 <- file.path(path, "filtered", paste0(sample.names2, "_R_trimmed_filt.fastq.gz"))
names(filtFs2) <- sample.names2
names(filtRs2) <- sample.names2
filtered_out2 <- filterAndTrim(fnFs2, filtFs2, fnRs2, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out2 <- filterAndTrim(fnFs, filtFs2, fnRs, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
filtered_out3 <- filterAndTrim(fnFs, filtFs2, fnRs, filtRs2, truncLen=c(250,200),
maxN=0, maxEE=c(2,5), truncQ=2, rm.phix=TRUE,
compress=TRUE, matchIDs = TRUE)
plotQualityProfile(filtFs2[1:2])
sample.names
rm(list = ls()) #clear out environment as needed.
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses")
library("ggplot2")
library("readxl")
library("dplyr")
library("tidyverse")
library("ggpubr")
library("ape")
library("lme4")
library("gplots")
library("plotly")
library("tidyr")
library("vegan")
library("psych")
library("openxlsx")
library("magrittr")
library("purrr")
library("reshape2")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses/")
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/MICOM_flux_and_pathway_analyses/")
library(tidyverse)
library(broom)
library(palmerpenguins)
install palmerpenguins
install.packages("palmerpenguins")
library(palmerpenguins)
penguins <- penguins %>%
drop_na() %>%
select(-year)
View(penguins)
pca_fit <- penguins %>%
select(where(is.numeric)) %>%
scale() %>%
prcomp()
summary(pca_fit)
pca_fit %>%
augment(penguins)
pca_fit %>%
augment(penguins) %>%
rename_at(vars(starts_with(".fitted")),
list(~str_replace(.,".fitted","")))
pca_fit %>%
augment(penguins) %>%
rename_at(vars(starts_with(".fitted")),
list(~str_replace(.,".fitted",""))) %>%
ggplot(aes(x=PC1,
y=PC2,
color=species,
shape=sex))+
geom_point()
library("ggplot2")
library("readxl")
library("dplyr")
library("tidyverse")
library("ggpubr")
library("ape")
library("lme4")
library("gplots")
library("plotly")
library("tidyr")
library("vegan")
library("psych")
library("openxlsx")
library("magrittr")
library("purrr")
library("reshape2")
#the goal here is to import differentially expressed genes and significantly different microbial fluxpaths from the Burns RNAseq data
#and my metabolic models (based on the Burns microbiome data) and correlate them.
#based on 09.13.21_correlating_Burns_GEs_and_GRs.R and 09.13.21_correlating_Burns_GEs_and_fluxpaths.R
#for the generation of the data used in this script, see
#05.14.21_calculating_log2foldchange_Burns_RNAseq_filtered_add_metabolism_filter_125_genes.py (for GEs)
#09.10.21_Burns2015_indiv_spp_GR_analysis.R (for GRs)
#10.21.21_BUrns2015_fluxpath_analysis_exchanges_only.R (for fluxes)
##########Preliminary steps
rm(list = ls()) #clear out environment as needed.
setwd("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Analyzing_MICOM_communities_Burns2015/")
##############Growth rates##############
############step 1: import files
genus_stat_results <- read_csv("09.10.21_filtered_microbial_GR_sig_results_Burns2015_data.csv") #used to be top_genera
genus_stat_results <- select(genus_stat_results, -c(...1))
genus_growth_rates <-read_csv("09.10.21_filtered_microbial_GR_data_Burns2015_data.csv") #used to be growth_rates_all
genus_growth_rates <- select(genus_growth_rates, -c(...1))
#goal: filter this dataframe by the top_ten_genera dataframe. In that, genus_ids_point_one has the identifier family_genus
#remove all rows where Diff_direction is no change; this is because a) who cares, b) those GRs
#are zero anyway, and c) it gives a -inf value for log2GRs, which will screw with everything unless I remove it.
genus_growth_rates <- subset(genus_growth_rates, Difference_direction != "Zero change")
#this removes ~40 rows, which is fine.
############step 2: filter growth_rates_all by top_ten_genera to pull out growth rates of top 20 taxa only
#take a vector of the genus_ids_point_one from top_ten_genera
top_genera_names <- pull(genus_stat_results,genus_ids_point_one) #make a vector from a column:thanks dplyr!
#use that to filter on the new column
growth_rates_top_genera <- filter(genus_growth_rates, famgen_col %in% top_genera_names) #thanks again dplyr!
############step 3: calculate log2(tumor v normal GRs)- needed b/c we're taking log2fold change of genes.
#add 1 to each column (needed for taking the log of things)
growth_rates_top_genera$growth_rate_normal_adj <- growth_rates_top_genera$mean_genus_GR_normal + 1
growth_rates_top_genera$growth_rate_tumor_adj <- growth_rates_top_genera$mean_genus_GR_tumor + 1
#calculate log2 values and put into new column
growth_rates_top_genera[,c("log2_growth_rate_normal","log2_growth_rate_tumor")] <- log2(growth_rates_top_genera[,c("growth_rate_normal_adj","growth_rate_tumor_adj")])
############Step 4: average across OTUs that appear more than once in the same Patient_Blind_ID
#note here that we're only doing tumor GRs, because that's all we care about at this point.
#first, create a new dataframe containing only relevant columns
growth_rates_subset <- growth_rates_top_genera[ , names(growth_rates_top_genera) %in% c("Patient_Blind_ID", "log2_growth_rate_tumor", "OTU_ID", "famgen_col")]
#then create a new sorting column to get unique values for each famgen_col/Patient_Blind_ID combo
growth_rates_subset <- growth_rates_subset %>%
mutate(sorting_col = paste0(famgen_col, "_", Patient_Blind_ID))
#then average across famgen_col :
growth_rates_subset_averaged <- growth_rates_subset %>%        # Specify data frame
group_by(sorting_col, Patient_Blind_ID, famgen_col) %>%    # Specify group indicator
summarise_at(vars(log2_growth_rate_tumor),                   # Specify column
list(av_log2GR_tumor = mean))         # Specify function
growth_rates_subset_averaged <- growth_rates_subset_averaged[ , ! names(growth_rates_subset_averaged) %in% c("sorting_col")] #drop sorting column
############Step 5: convert dataframe to wide and set row names as Patient_Blind_ID for correlating
growth_rates_subset_wide <- spread(growth_rates_subset_averaged, famgen_col, av_log2GR_tumor) #convert dataframe to wide
growth_rates_subset_wide <- column_to_rownames(growth_rates_subset_wide, var = "Patient_Blind_ID") #set Patient_Blind_ID as row names
#hooray! Now we have a dataframe for correlating.
#clean up
rm(genus_growth_rates, growth_rates_subset, growth_rates_subset_averaged, growth_rates_top_genera, genus_stat_results, top_genera_names)
##############Fluxes##############
############step 1: import files
flux_values <- read_csv("10.25.21_filtered_sum_exchange_fluxes_only_alldata_Burns2015_data.csv") #used to be fluxes_top_diffs
flux_values <- select(flux_values, -c(...1))
flux_stats <-read_csv("10.25.21_filtered_sum_exchange_fluxes_only_stats_Burns2015_data.csv") #used to be fluxes_all
flux_stats <- select(flux_stats, -c(...1))
flux_stats <- flux_stats %>% top_n(-20, by_flux_pvals)
#take a vector of the genus_ids_point_one from top_ten_genera
top_flux_names <- pull(flux_stats,flux_ids) #make a vector from a column:thanks dplyr!
#use that to filter on the new column
fluxes_top_pathways <- filter(flux_values, fluxpath_name %in% top_flux_names) #thanks again dplyr!
#then, rename columns
fluxes_top_pathways <- fluxes_top_pathways %>% rename(fluxes_normal = normal, fluxes_tumor = tumor) #rename columns
fluxes_top_pathways$Patient_Blind_ID <- as.factor(fluxes_top_pathways$Patient_Blind_ID)
############step 3: calculate log2(import) and log2(export) fluxes for tumor samples only- needed b/c we're taking log2fold change of genes.
flux_values_nonegs <- fluxes_top_pathways  %>%
mutate(tumor_flux_direction = case_when(
fluxes_tumor >0 ~ "_import",
fluxes_tumor < 0 ~ "_export"))
#then convert all negative fluxes to positive values.
flux_values_nonegs$fluxes_tumor <- abs(flux_values_nonegs$fluxes_tumor)
#NOW we can take the log value
flux_values_nonegs[,c("log2_fluxes_tumor")] <- log2(flux_values_nonegs[,c("fluxes_tumor")])
#finally, we want to make sure the import/export direction is preserved, so we'll append it to the fluxpath_name column
flux_values_nonegs$flux_ids_dirs <- str_c(flux_values_nonegs$fluxpath_name,"",flux_values_nonegs$tumor_flux_direction)
#haha if we use stringr vs tidyr, we don't have to rearrange the columns.
flux_values_cleaned <- subset(flux_values_nonegs, select = -c(fluxpath_name,fluxes_normal,fluxes_tumor,diff,Difference_direction,tumor_flux_direction))
flux_values_wide <- spread(flux_values_cleaned, flux_ids_dirs, log2_fluxes_tumor) #convert dataframe to wide
flux_values_wide <- column_to_rownames(flux_values_wide, var = "Patient_Blind_ID") #set Patient_Blind_ID as row names
#ugh..... we should only have 20 metabolte exchanges, but because of the import/export thing, we get 31. How to contend with the fact that different samples
#have net export vs net import....
#do we maybe just... make the log values negative? No, we can't do that. negative log2 values happen when the original value is less than one.
#maybe I just... don't transform.
flux_values_notfn_cleaned <- subset(fluxes_top_pathways, select = -c(fluxes_normal,diff,Difference_direction))
flux_values_notfn_wide <- spread(flux_values_notfn_cleaned, fluxpath_name, fluxes_tumor) #convert dataframe to wide
flux_values_notfn_wide <- column_to_rownames(flux_values_notfn_wide, var = "Patient_Blind_ID") #set Patient_Blind_ID as row names
#clean up
rm(flux_stats, flux_values, top_flux_names, flux_values_cleaned, flux_values_nonegs, fluxes_top_pathways, flux_values_notfn_cleaned)
host_gene_expression <- read_csv("/Users/adamo010/Documents/MICOM_CRC_FBA/Individual_specific_microbiomes/Common_growth_medium_runs/Jan_May2021_MICOM_GR_analyses/Correlating_GE_with_GRs_Burns_data/05.14.21_log2foldchange_gene_expression_top_125_metabolic_DEGs_matrix.csv") #the row_names note makes sure the Patient_blind_ids are set as row names
host_gene_expression <- column_to_rownames(host_gene_expression, var = "Patient_Blind_ID") #set Patient_Blind_ID as row names
#note here that we've already filtered by the top 125 genes in the python script that generated this file;
#see 05.14.21_calculating_log2foldchange_Burns_RNAseq_filtered_add_metabolism_filter_125_genes.py for that code
#also, no need to do any dataframe manipulation. It's all ready to go!
##############CORRELATING##############
##########Step 1: prep dataframes
#order dataframes by row name (Patient_Blind_ID)
host_gene_expression <- host_gene_expression[ order(as.numeric(row.names(host_gene_expression))), ]
growth_rates_subset_wide <- growth_rates_subset_wide[ order(as.numeric(row.names(growth_rates_subset_wide))), ]
#flux_values_wide not used
flux_values_notfn_wide <- flux_values_notfn_wide [ order(as.numeric(row.names(flux_values_notfn_wide ))), ]
gr_ge_correlations <- corr.test(growth_rates_subset_wide, host_gene_expression, use = "pairwise",method="spearman",adjust="BH", alpha=.05,ci=TRUE,minlength=5)
#fluxpath_correlations
fluxpath_ge_correlations <- corr.test(flux_values_notfn_wide, host_gene_expression, use = "pairwise",method="spearman",adjust="BH", alpha=.05,ci=TRUE,minlength=5)
###########Step 3: Filtering and graphing
#gr_correlations: corrected and uncorrected p-values, and r-values
gr_correlations_corrected <- as.data.frame(gr_ge_correlations$p.adj) #this makes a dataframe
gr_correlations_corrected <- tibble::rownames_to_column(gr_correlations_corrected, "taxon_name") #THANKS DPLYR, hero of R!
gr_correlations_uncorrected <- as.data.frame(gr_ge_correlations$p) #this makes a dataframe
gr_correlations_uncorrected <- tibble::rownames_to_column(gr_correlations_uncorrected, "taxon_name") #THANKS DPLYR, hero of R!
gr_correlations_rvals <- as.data.frame(gr_ge_correlations$r) #this makes a dataframe
gr_correlations_rvals <- tibble::rownames_to_column(gr_correlations_rvals, "taxon_name") #THANKS DPLYR, hero of R!
#fluxpath_correlations: corrected and uncorrected p-values, and r-values
fluxpath_correlations_corrected <- as.data.frame(fluxpath_ge_correlations$p.adj) #this makes a dataframe
fluxpath_correlations_corrected <- tibble::rownames_to_column(fluxpath_correlations_corrected, "fluxpath_name") #THANKS DPLYR, hero of R!
fluxpath_correlations_uncorrected <- as.data.frame(fluxpath_ge_correlations$p) #this makes a dataframe
fluxpath_correlations_uncorrected <- tibble::rownames_to_column(fluxpath_correlations_uncorrected, "fluxpath_name") #THANKS DPLYR, hero of R!
fluxpath_correlations_rvals <- as.data.frame(fluxpath_ge_correlations$r) #this makes a dataframe
fluxpath_correlations_rvals <- tibble::rownames_to_column(fluxpath_correlations_rvals, "fluxpath_name") #THANKS DPLYR, hero of R!
gr_correlations_corrected_long <- gr_correlations_corrected %>%
melt(id.var="taxon_name") %>%
arrange(taxon_name, variable)
gr_correlations_corrected_long <- rename(gr_correlations_corrected_long, c("gene_id"="variable", "p_value_adj"="value")) #rename columns
#
gr_correlations_uncorrected_long <- gr_correlations_uncorrected %>%
melt(id.var="taxon_name") %>%
arrange(taxon_name, variable)
gr_correlations_uncorrected_long <- rename(gr_correlations_uncorrected_long, c("gene_id"="variable", "p_value_raw"="value")) #rename columns
#
gr_correlations_rvals_long <- gr_correlations_rvals %>%
melt(id.var="taxon_name") %>%
arrange(taxon_name, variable)
gr_correlations_rvals_long <- rename(gr_correlations_rvals_long, c("gene_id"="variable", "R_value"="value")) #rename columns
###
fluxpath_correlations_corrected_long <- fluxpath_correlations_corrected %>%
melt(id.var="fluxpath_name") %>%
arrange(fluxpath_name, variable)
fluxpath_correlations_corrected_long <- rename(fluxpath_correlations_corrected_long, c("gene_id"="variable", "p_value_adj"="value")) #rename columns
fluxpath_correlations_uncorrected_long <- fluxpath_correlations_uncorrected %>%
melt(id.var="fluxpath_name") %>%
arrange(fluxpath_name, variable)
fluxpath_correlations_uncorrected_long <- rename(fluxpath_correlations_uncorrected_long, c("gene_id"="variable", "p_value_raw"="value")) #rename columns
#
fluxpath_correlations_rvals_long <- fluxpath_correlations_rvals %>%
melt(id.var="fluxpath_name") %>%
arrange(fluxpath_name, variable)
fluxpath_correlations_rvals_long <- rename(fluxpath_correlations_rvals_long, c("gene_id"="variable", "R_value"="value")) #rename columns
gr_correlations_long_merged <- merge(merge(gr_correlations_corrected_long,
gr_correlations_uncorrected_long, all=TRUE),
gr_correlations_rvals_long, all=TRUE)
gr_correlations_long_merged <- gr_correlations_long_merged[order(gr_correlations_long_merged$p_value_raw),] #sort by p-value
fluxpath_correlations_long_merged <- merge(merge(fluxpath_correlations_corrected_long,
fluxpath_correlations_uncorrected_long, all=TRUE),
fluxpath_correlations_rvals_long, all=TRUE)
fluxpath_correlations_long_merged <- fluxpath_correlations_long_merged[order(fluxpath_correlations_long_merged$p_value_raw),] #sort by p-value
View(fluxpath_correlations_long_merged)
